import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px



# Charger les donn√©es uniquement si elles ne sont pas encore pr√©sentes dans la session
if 'df' not in st.session_state:
    st.session_state.df = pd.read_csv("data/5_LFB_fusion.csv")

# Acc√©der aux donn√©es depuis session_state
df = st.session_state.df



@st.cache_data
def analyser_df(df):
    analyse = pd.DataFrame({
        'Nb NaN': df.isna().sum(),
        '% NaN': df.isna().mean() * 100,
        'Nb valeurs uniques': df.nunique()
    })
    return analyse




st.sidebar.title("Sommaire")
st.sidebar.image("logo DST.png", width=75)
pages = ["Introduction", "Distribution", "Enrichissement", "Datavisualisation","Preprocessing", "Mod√©lisation","Conclusion"]
page = st.sidebar.radio("Aller vers", pages)

# Affichage de l'image principale
st.image("Lfb_logo.jpg", width=75)

# === Page - Introduction ===


if page == "Introduction":
    st.title("Temps de r√©ponse des pompiers (LFB)")
    st.header("Introduction")
    st.markdown(
        "La London Fire Brigade (LFB) met √† disposition sur son site officiel les donn√©es relatives aux incidents enregistr√©s depuis janvier 2009, ainsi que les informations concernant les camions de pompiers envoy√©s sur les lieux des incidents.  \n\n"
        "Ce rapport est bas√© sur l‚Äôexploration et le traitement de ces donn√©es dans le but d‚Äôanalyser et d‚Äôestimer le temps de r√©action de la LFB.  \n\n"
        "Les casernes de pompiers de la LFB sont strat√©giquement situ√©es pour atteindre un d√©lai moyen d'intervention inf√©rieur ou √©gal √† 6 minutes.  \n\n"
        "L‚Äôobjectif de ce projet est d‚Äôanalyser les temps de r√©ponse de la brigade des pompiers de Londres et √©ventuellement pr√©dire ces temps de r√©ponses.")
    

elif page == "Distribution":
    @st.cache_data
    def analyser_df(df):
        return pd.DataFrame({
        '% NaN': df.isna().mean() * 100,
        'Nb valeurs uniques': df.nunique()})

    def get_value_counts(df, column, top_n=20):
        value_counts = df[column].value_counts(dropna=False).head(top_n)
        value_counts_df = value_counts.reset_index()
        value_counts_df.columns = [column, 'Nombre']
        value_counts_df['%'] = (value_counts_df['Nombre'] / value_counts_df['Nombre'].sum()) * 100
        return value_counts_df

# Analyse des donn√©es
    resultats = analyser_df(df)
    st.dataframe(resultats)

# S√©lection d'une variable
    st.markdown("##### S√©lectionnez une variable cat√©gorielle :")
    variable = st.selectbox("Variable", df.columns)

    if variable:
        st.write(f"#### Distribution de la variable : {variable}")

    # Affichage de la distribution
        count_data = get_value_counts(df, variable, top_n=20)
        st.dataframe(count_data)


elif page == "Enrichissement":
    st.header("Enrichissement")
    st.markdown("Nous avons fait le choix de rajouter des *variables internes* en segmentant la date de r√©f√©rence : **en mois, jour de la semaine, ann√©e**)  et des *variables externes* issues de la base **m√©t√©o** pour la m√™me p√©riode.")
    
# Cr√©ation de trois onglets
    tab1, tab2 = st.tabs(["Variables temporelles", "Variables m√©t√©o"])

# Contenu du premier onglet
    with tab1:
        st.header("Variables temporelles")
        st.write("Pour faciliter la pertinence de la datavisualisation, nous avons segementer la date compl√®te avec de nouvelles variables")

# Contenu du deuxi√®me onglet
    with tab2:
        st.header("Variables M√©t√©o")
        st.write("Voici quelques visualisations ou analyses.")


elif page == "Datavisualisation":
    st.header("Datavisualisation")
    st.write("### Visualisation interactive des variables ")
    tab1, tab2, tab3 = st.tabs(["Dataviz Univari√©e", "Dataviz Multivari√©e", "Heatmap"])
    with tab1:
        st.header("Dataviz Univari√©e")
        st.write("Pour faciliter la pertinence de la datavisualisation, nous avons segment√© la date compl√®te avec de nouvelles variables.")

        # Boxplot interactif avec Plotly
        fig_box = px.box(df, 
                         x="FirstPumpArriving_AttendanceTime", 
                         title="D√©lai d'arriv√©e du premier camion de pompier")
        st.plotly_chart(fig_box)

        # Seaborn countplot
        fig, ax = plt.subplots()
        sns.countplot(data=df, x="IncidentGroup", hue="IncidentGroup", ax=ax)
        ax.set_xlabel("Type d'incident")
        ax.set_ylabel("Quantit√©")
        ax.set_yticks(range(0, 800, 200))
        ax.set_title("Nombre d'incidents par cat√©gorie")
        ax.legend().remove()
        plt.tight_layout()
        st.pyplot(fig)

    
    # üìà Onglet 2 : Dataviz multivari√©e
    with tab2:
        st.header("Dataviz multivari√©e")
        with st.expander("Type d'incident") :
            fig2, ax2 = plt.subplots()
            sns.violinplot(data=df, x="StopCodeDescription",  y="FirstPumpArriving_AttendanceTime",hue="StopCodeDescription", palette="Set1")      
            ax2.set_title("Relation entre le type d'incident et le d√©lai de r√©ponse")
            ax2.set_xlabel("Type d'incident")
            ax2.set_ylabel("D√©lai de r√©ponse de la LFB")
            plt.xticks(rotation = 90)
            plt.tight_layout()
            st.pyplot(fig2)

    # üî• Onglet 3 : Heatmap
    with tab3:
        st.header("Heatmap")
        st.write("Carte thermique des corr√©lations entre variables num√©riques.")
        #Renommer une variable
        df = df.rename(columns = {"Notional Cost (¬£)":"National Cost","VISIBILITY_AVG_KM":"Visibility"})
        df["CalYear"] = df["CalYear"].astype(object)
        df["HourOfCall"] = df["HourOfCall"].astype(object)
        df["UPRN"] = df["UPRN"].astype(object)
        df["USRN"] = df["USRN"].astype(object)
        df["Easting_m"] = df["Easting_m"].astype(object)
        df["Northing_m"] = df["Northing_m"].astype(object)
        df["Easting_rounded"] = df["Easting_rounded"].astype(object)
        df["Northing_rounded"] = df["Northing_rounded"].astype(object)
        df["Latitude"] = df["Latitude"].astype(object)
        df["Longitude"] = df["Longitude"].astype(object)
        df["ResourceMobilisationId"] = df["ResourceMobilisationId"].astype(object)
        df["PumpOrder"] = df["PumpOrder"].astype(object)
        df["PerformanceReporting"] = df["PerformanceReporting"].astype(object)
        df["DelayCodeId"] = df["DelayCodeId"].astype(object)
        numeric_df = df.select_dtypes(include='number')  # S√©lection des colonnes num√©riques
        corr = numeric_df.corr()
        fig3, ax3 = plt.subplots(figsize=(9,9))
        sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax3)
        st.pyplot(fig3)


elif page == "Preprocessing":
    st.header("Preprocessing")
    tabs = st.tabs(["Split","Frequency Encoding", "OneHotEncoder", "Label Encoding", "Standardisation"])

# Contenu du premier onglet
    with tabs[0]:
        st.header("Split")

    with tabs[1]:
        st.header("requency Encoding")
        st.write("Contenu pour l'onglet 'requency Encoding'.")

    with tabs[2]:
        st.header("OneHotEncoder")
        st.write("Contenu pour l'onglet 'OneHotEncoder'.")

    with tabs[3]:
        st.header("Label Encoding")
        st.write("Contenu pour l'onglet 'Label Encoding'.")
    
    with tabs[4]:
        st.header("Split")
        st.write("Contenu pour l'onglet 'Standardisation'.")


elif page == "Mod√©lisation":
    st.header("Mod√©lisation")
    
        # Graphique de r√©gression (affichage de la relation entre la cible et une feature)
    with st.expander("Mod√®les de R√©gression"):
        st.markdown("""
        **Mod√®les test√©s :**
        - Linear Regression
        - Decision Tree Regressor
        - Random Forest Regressor
        - SGD Regressor
        - KNN Regressor
        """)
        data = [[89.719590, 14049.171200, 118.529200, 0.051449], [207.2518553, 63919.102367, 252.82227427, -3.319882904], [88.149152936, 13649.741853, 116.832109685, 0.0797185175],[219791737230162, 4.928111e+30, 2219934929759535, 3.32472727e+26],[94.106070, 15144.089260, 123.061323, -0.022476]]  
        df = pd.DataFrame(data, columns = ["MAE", "MSE", "RMSE", "R2"], index =["Linear_Regression", "Decision_Tree_Regressor", "Random_Forest_Regressor", "SGD_Regressor", "KNNRegressor"])
        st.dataframe(df)

        
        
        # Classification binaire
    with st.expander("Mod√®les de Classification binaire"):
        st.markdown("""
        **Mod√®les test√©s :**
        - Logistic Regression
        - Decision Tree Classifier
        - Random Forest Classifier
        - XGB Classifier
        - KNN Classifier
        - Linear SVC
        """)
        data = [
        [0.71, 0.54, 0.71, 0.00, 1.00, 0.00, 0.83],
        [0.70, 0.49, 0.79, 0.49, 0.79, 0.49, 0.79],
        [0.74, 0.61, 0.77, 0.31, 0.92, 0.41, 0.84],
        [0.73, 0.68, 0.74, 0.15, 0.97, 0.24, 0.84],
        [0.69, 0.37, 0.72, 0.09, 0.93, 0.15, 0.81],
        [0.71, 0.59, 0.71, 0.00, 1.00, 0.01, 0.83]]

        df2 = pd.DataFrame(data,columns=[
            "Accuracy",
            "Precision Classe 0", "Precision Classe 1",
            "Recall Classe 0", "Recall Classe 1",
            "F1 Score Classe 0", "F1 Score Classe 1"],
        index=[
            "Logistic Regression", "Decision Tree Classifier",
            "Random Forest Classifier", "XGB Classifier",
            "KNN Classifier", "Linear SVC"])

        st.dataframe(df2)

        # Classification multi-classes
    with st.expander("Mod√®les de Classification multi-classes"):
        st.markdown("""
        **Mod√®les test√©s :**
        - Logistic Regression
        - Decision Tree Classifier
        - Random Forest Classifier
        - XGB Classifier
        - KNN Classifier 
        """)
        data = [[0.32, 0.33, 0.25, 0.30,0.32,0.67,0.00,0.34,0.19,0.44,0.00,0.32,0.24], [0.40, 0.51, 0.31, 0.35,0.41,0.51,0.32,0.35,0.40, 0.51,0.31,0.35,0.40],[0.42,0.50,0.33,0.37,0.45,0.60,0.27,0.37,0.41,0.55,0.3,0.37,0.43],[0.39, 0.42, 0.36,0.35,0.41, 0.66,0.08,0.38,0.39,0.51,0.13,0.36,0.40],[0.28, 0.31, 0.24, 0.28, 0.27,0.45,0.21,0.23,0.20,0.37,0.22,0.25,0.23]]  
        df3= pd.DataFrame(data, columns = ["ACCURACY", "PRECISION  Classe 0", "PRECISION Classe 1","PRECISION Classe 2","PRECISION Classe 3", "RECALL Classe 0", "RECALL Classe 1", "RECALL Classe 2", "RECALL Classe 3","F1 SCORE Classe 0","F1 SCORE Classe 1","F1 SCORE Classe 2","F1 SCORE Classe 3"], index =["Logistic Regression", "Decision Tree Classifier", "Random Forest Classifier", "XGB Classifier", "KNN Classifier"])
        st.dataframe(df3)    

    with st.expander("Mod√®le optimis√©"):
        st.markdown("""
        **Mod√®les optimis√©s test√©s :**
        - Decision Tree Classifier
        - Random Forest Classifier 
        """)
        data = [[0.42, 0.49, 0.62, 0.55], [0.42, 0.33, 0.25, 0.29], [0.42, 0.36, 0.39, 0.38],[0.42, 0.47, 0.36, 0.41]]  
        df4 = pd.DataFrame(data, columns = ["ACCURACY", "PRECISION", "RECALL", "F1 SCORE"], index =["Classe 0", "Classe 1", "Classe 2", "Classe 3"])
        st.dataframe(df4)